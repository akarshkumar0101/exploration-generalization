# python cluster_run.py /data/vision/phillipi/akumar01/exploration-generalization/atari/scripts/finetuning_ppo.sh --mem-gpu 4000 --dir /data/vision/phillipi/akumar01/exploration-generalization/atari --servers visiongpu37 visiongpu36 visiongpu35 visiongpu33 visiongpu32 visiongpu29 visiongpu23 visiongpu22 visiongpu21 visiongpu20 visiongpu19 visiongpu18 visiongpu17 visiongpu16 visiongpu15 visiongpu14 visiongpu13 visiongpu12 visiongpu11 --conda-env atari
# requires 4 GB of GPU memory

python_file: train.py

--track: True
--project: egb-atari-ftppo
--name: "finetune_ppo_{env_ids[0]}_{obj}_{pre_obj}_history_{pre_teacher_last_k}_{seed}"
--log-video: False
--log-hist: False

--device: cuda
--seed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]

# Test: MsPacman # Pong # SpaceInvaders # StarGunner # Boxing
# --env-ids: [MsPacman, Pong, SpaceInvaders, StarGunner, Boxing]
--env-ids: [Boxing]
--obj: ext
--total-steps: 1e6
--n-envs: 16
--n-steps: 128
--batch-size: 2048
--n-updates: 4

--model: gpt
--ctx-len: 4
--load-agent: "./data/egb-atari/generalist_30_{pre_obj}_history_{pre_teacher_last_k}_{seed}/agent_000000320.pt"
--save-agent: "./data/{project}/{name}/"
--full-action-space: True

--lr: 2.5e-4
--lr-warmup: True
--lr-decay: "none"
--max-grad-norm: 1.0


--episodic-life: False
--norm-rew: True
--gamma: 0.99
--gae-lambda: 0.95
--norm-adv: True
--ent-coef: 0.001
--clip-coef: 0.1
--vf-coef: 0.5
# --max-kl-div: 0.01

--pre-obj: [None, ext, rnd]
--train-klbc: False
--model-teacher: cnn
--ctx-len-teacher: 4
--load-agent-teacher: "./data/{project}/specialist_{{env_id}}_{obj}_0/"
--teacher-last-k: [1]
--pre-teacher-last-k: [1, 8]

--n-steps-rnd-init: 0
